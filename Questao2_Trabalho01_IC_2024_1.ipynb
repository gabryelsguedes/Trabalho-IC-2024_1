{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Para comparar com os resultados do artigo foi necessário fazer a média tanto do RMSE quanto do coeficiente de determinação, pois eles estavam divididos por regiões.\n",
        "\n",
        "\n",
        "O coeficiente de determinação é uma medida estatística que avalia a proporção da variância da variável dependente que é explicada pelas variáveis independentes em um modelo de regressão.\n",
        "\n",
        "Um R² alto sugere que parte da variância dos dados é explicada pelo modelo, porém não indica causalidade, apenas correlação. Um R² baixo indica que o modelo não está detectando a relação entre as variáveis.\n",
        "\n",
        "O RMSE (Root Mean Square Error) é a raiz quadrada da média dos erros quadráticos (diferenças ao quadrado entre as previsões e os valores reais). Isso garante que o RMSE está na mesma unidade que os valores da variável dependente.\n",
        "\n",
        "Como os erros são elevados ao quadrado o RMSE é mais sensível a outliers, significando que erros grandes aumentam o valor do RMSE, ou seja, os outliers causam maior atenção na métrica do modelo do que os erros de valores baixos."
      ],
      "metadata": {
        "id": "FH5uPqC0rN3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:,1:7].values\n",
        "y = data.iloc[:,7].values\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste (70% treino, 30% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Treinamento do modelo de Regressão Linear Múltipla\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo de Regressão Linear Múltipla\n",
        "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Resultados\n",
        "print(\"Resultados da Regressão Linear Múltipla:\")\n",
        "print(f\"RMSE: {rmse_linear}\")\n",
        "print(f\"R²: {r2_linear}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXB9p7lLUZNv",
        "outputId": "166c07e0-da2c-412d-86be-f0149e2b0867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados da Regressão Linear Múltipla:\n",
            "RMSE: 8.57703316536862\n",
            "R²: 0.5600810475775289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro modelo testado foi com o uso de regressão linear simples com uma divisão dos dados de treino e teste em 70%-30% e como métrica de avaliação os valores de RMSE e R²(Coeficiente de determinação), assim como o utilizado no artigo de comparação da questão.\n",
        "\n",
        "No primeiro modelo não foi realizado qualquer pré processamento dos dados. Após a aplicação os resultados obtidos foram de RMSE:8,57 e R²: 0,56.\n",
        "\n",
        "Os dados dos artigos apresentaram os valores de RMSE:8,042 e R²:0,396.\n",
        "\n",
        "O primeiro modelo apresentou um valor RMSE bem próximo ao do artigo, porém no modelo aplicado o R² apresentou um melhor ajuste dos dados ao modelo em termos de variância explicada."
      ],
      "metadata": {
        "id": "5nR3TQo3keeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:,1:7].values\n",
        "y = data.iloc[:,7].values\n",
        "\n",
        "# Aplicando a normalização nas variáveis independentes (X)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste (70% treino, 30% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Treinamento do modelo de Regressão Linear Múltipla\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo de Regressão Linear Múltipla\n",
        "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Resultados\n",
        "print(\"Resultados da Regressão Linear Múltipla com Normalização:\")\n",
        "print(f\"RMSE: {rmse_linear}\")\n",
        "print(f\"R²: {r2_linear}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxoP7jC3VTSw",
        "outputId": "ea6254e3-3f31-49fd-bbc6-69d955d0d14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados da Regressão Linear Múltipla com Normalização:\n",
            "RMSE: 8.577033165368846\n",
            "R²: 0.5600810475775057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A aplicação da normalização dos dados não apresentou resultados diferentes ao primeiro modelo sem normalização.\n",
        "\n",
        "A normalização geralmente é aplicada para evitar viés entre os dados de entrada, pois possuem unidades de medidas diferentes, sendo alguns dados de entrada com valores altos e outros com baixos valores, o que acaba por causar uma maior influência dos dados de maiores valores em detrimento aos de baixos valores.\n",
        "\n",
        "Porém no modelo em questão não foi observada tal situação."
      ],
      "metadata": {
        "id": "v_rIM-XqsSV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:,1:7].values\n",
        "y = data.iloc[:,7].values\n",
        "\n",
        "# Aplicando a normalização nas variáveis independentes (X)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Definindo o número de folds para validação cruzada\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Criando o modelo de Regressão Linear Múltipla\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Aplicando a validação cruzada com KFold (métrica: RMSE negativa)\n",
        "rmse_scores = -cross_val_score(linear_model, X_scaled, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "# Aplicando a validação cruzada com KFold para o coeficiente de determinação R²\n",
        "r2_scores = cross_val_score(linear_model, X_scaled, y, cv=kf, scoring='r2')\n",
        "\n",
        "# Exibindo os resultados\n",
        "print(\"Validação Cruzada com KFold (5 folds):\")\n",
        "print(f\"RMSE Médio: {np.mean(rmse_scores)}\")\n",
        "print(f\"RMSE Desvio Padrão: {np.std(rmse_scores)}\")\n",
        "print(f\"R² Médio: {np.mean(r2_scores)}\")\n",
        "print(f\"R² Desvio Padrão: {np.std(r2_scores)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d31PZbWMVu7E",
        "outputId": "02e41523-f1fc-4694-853c-68395e838b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validação Cruzada com KFold (5 folds):\n",
            "RMSE Médio: 8.795887495288861\n",
            "RMSE Desvio Padrão: 1.3157038136391592\n",
            "R² Médio: 0.569326961195446\n",
            "R² Desvio Padrão: 0.09144352526115428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em um terceiro momento foi aplicado além da normalização dos dados a validação cruzada com o uso do k-fold. Essa técnica é utilizada para realizar o treinamento do modelo e tem como objetivo mitigar sobreajuste, avaliar de forma mais abrangente o desenvolvimento do modelo e melhoria na generalização dos dados.\n",
        "\n",
        "Nesse modelo, os dados são divididos em subconjuntos K de tamanhos aproximadamente iguais. Durante a fase de treinamento e teste, um dos Kfolds é armazenado para teste e os outros usados para treinamento. Esses testes ocorrem de forma recursiva e todos os kfolds são utilizados como teste.\n",
        "\n",
        "O resultado é apresentado com o uso da média e desvio padrão para apresentar uma estimativa do desempenho do modelo.\n",
        "\n",
        "Observando as métricas de saída, a validação cruzada apresentou um valor médio próximo aos outros modelos e ao modelo do artigo."
      ],
      "metadata": {
        "id": "UHi6X84EtZ76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:,1:7].values\n",
        "y = data.iloc[:,7].values\n",
        "\n",
        "# Aplicando a normalização nas variáveis independentes (X)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Aplicando PCA para manter 95% da variância\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Exibir a variância explicada por cada componente\n",
        "print(f\"Variância explicada por cada componente: {pca.explained_variance_ratio_}\")\n",
        "print(f\"Número de componentes selecionados: {pca.n_components_}\")\n",
        "\n",
        "# Definindo o número de folds para validação cruzada\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Criando o modelo de Regressão Linear Múltipla\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Aplicando a validação cruzada com KFold (métrica: RMSE negativa)\n",
        "rmse_scores = -cross_val_score(linear_model, X_pca, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "# Aplicando a validação cruzada com KFold para o coeficiente de determinação R²\n",
        "r2_scores = cross_val_score(linear_model, X_pca, y, cv=kf, scoring='r2')\n",
        "\n",
        "# Exibindo os resultados\n",
        "print(\"Validação Cruzada com KFold (5 folds) após PCA:\")\n",
        "print(f\"RMSE Médio: {np.mean(rmse_scores)}\")\n",
        "print(f\"RMSE Desvio Padrão: {np.std(rmse_scores)}\")\n",
        "print(f\"R² Médio: {np.mean(r2_scores)}\")\n",
        "print(f\"R² Desvio Padrão: {np.std(r2_scores)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I4cULMLWQ0n",
        "outputId": "d38acab9-cb7d-4621-8c9d-f84bdcb2b5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variância explicada por cada componente: [0.36742321 0.28164928 0.20145538 0.09221749 0.04246124]\n",
            "Número de componentes selecionados: 5\n",
            "Validação Cruzada com KFold (5 folds) após PCA:\n",
            "RMSE Médio: 8.849548838797208\n",
            "RMSE Desvio Padrão: 1.3654358043988348\n",
            "R² Médio: 0.56474522612371\n",
            "R² Desvio Padrão: 0.09099666469095057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo principal do PCA é reduzir a dimensionalidade de conjuntos de dados, preservando o máximo possível de variância.\n",
        "\n",
        "Ele transforma um conjunto de variáveis possivelmente correlacionadas em um conjunto menor de variáveis não correlacionadas chamadas componentes principais.\n",
        "\n",
        "Essa técnica é utilizada para manter a maior parte da variância dos dados originiais, assim, os primeiro componentes principais são os responsáveis pelas maiores partes da variância e isso permite diminuir o tamanho dos dados e manter uma elevada variância.\n",
        "\n",
        "A aplicação do PCA + Kfold + Normalização dos dados também não apresentaram valoers significativamente relevantes se comparados aos outros modelos e ao modelo do artigo em questão.\n",
        "\n"
      ],
      "metadata": {
        "id": "sXUij9_LweYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Modelos| RMSE |R²|\n",
        "|-------|------|------|\n",
        "|Regressão Linear (Yeh et.al)|8,042|0,396|\n",
        "|Regressão Linear Múltipla |8.577|0.560|\n",
        "|Resultados da Regressão Linear Múltipla com Normalização|8.577|0.560|\n",
        "|Validação Cruzada com KFold (5 folds)|8.796 ± 1.315|0.569 ± 0.0914|\n",
        "|Validação Cruzada com KFold (5 folds) após PCA|8.849 ± 1.365|0.565 ± 0.0909|"
      ],
      "metadata": {
        "id": "lq7K6wZyyHvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "83QQX9LRZjjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:,1:7].values\n",
        "y = data.iloc[:,7].values\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste (70% treino, 30% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Definindo a quantidade de neurônios da camada oculta: Regra Kolgomorov\n",
        "nno = 2 * len(X[0]) +1\n",
        "\n",
        "# Definindo o modelo MLP com TensorFlow (Keras)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(nno, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(1)  # Camada de saída com 1 neurônio para regressão\n",
        "])\n",
        "\n",
        "# Compilando o modelo (utilizando otimizador Adam e erro quadrático médio como perda)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Treinamento do modelo MLP\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred_mlp = model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo MLP\n",
        "rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))\n",
        "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "\n",
        "# Resultados\n",
        "print(\"Resultados do MLP com TensorFlow:\")\n",
        "print(f\"RMSE: {rmse_mlp}\")\n",
        "print(f\"R²: {r2_mlp}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGtY5W3OZ6M6",
        "outputId": "9c9fbae5-4517-409d-c4ac-9f822d226df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1158384.7500\n",
            "Epoch 2/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 679749.3125\n",
            "Epoch 3/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 441034.5938\n",
            "Epoch 4/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 278532.7500 \n",
            "Epoch 5/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 198331.2500 \n",
            "Epoch 6/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114301.1719 \n",
            "Epoch 7/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60934.4297   \n",
            "Epoch 8/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30133.3398  \n",
            "Epoch 9/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14630.4785 \n",
            "Epoch 10/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10191.9619  \n",
            "Epoch 11/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9012.2715  \n",
            "Epoch 12/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5965.5376  \n",
            "Epoch 13/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4985.7695 \n",
            "Epoch 14/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3763.1924  \n",
            "Epoch 15/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3115.8975 \n",
            "Epoch 16/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2689.4429  \n",
            "Epoch 17/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2138.3650  \n",
            "Epoch 18/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1951.8439  \n",
            "Epoch 19/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1595.9447 \n",
            "Epoch 20/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.1293 \n",
            "Epoch 21/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 729.0653 \n",
            "Epoch 22/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 629.3195  \n",
            "Epoch 23/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453.4135  \n",
            "Epoch 24/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 445.2029  \n",
            "Epoch 25/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 427.7392 \n",
            "Epoch 26/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 263.1048 \n",
            "Epoch 27/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.4336 \n",
            "Epoch 28/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 240.0457 \n",
            "Epoch 29/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.7671\n",
            "Epoch 30/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 176.5875 \n",
            "Epoch 31/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 206.9130 \n",
            "Epoch 32/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 306.1899  \n",
            "Epoch 33/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 170.0451\n",
            "Epoch 34/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 137.5883 \n",
            "Epoch 35/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 185.7448 \n",
            "Epoch 36/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 145.2754  \n",
            "Epoch 37/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97.6587  \n",
            "Epoch 38/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.0706  \n",
            "Epoch 39/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 128.3047\n",
            "Epoch 40/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 128.2457 \n",
            "Epoch 41/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 198.9619 \n",
            "Epoch 42/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 196.7779\n",
            "Epoch 43/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 156.4345 \n",
            "Epoch 44/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101.3937\n",
            "Epoch 45/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 156.9909 \n",
            "Epoch 46/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 123.1408 \n",
            "Epoch 47/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96.1099  \n",
            "Epoch 48/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 199.8648\n",
            "Epoch 49/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 97.9527 \n",
            "Epoch 50/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 141.4186\n",
            "Epoch 51/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 125.3353\n",
            "Epoch 52/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.0862\n",
            "Epoch 53/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.6453 \n",
            "Epoch 54/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 156.0944\n",
            "Epoch 55/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99.0422  \n",
            "Epoch 56/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 99.2635  \n",
            "Epoch 57/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.3163  \n",
            "Epoch 58/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96.7330 \n",
            "Epoch 59/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.8861 \n",
            "Epoch 60/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103.8898 \n",
            "Epoch 61/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101.8211\n",
            "Epoch 62/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108.9705 \n",
            "Epoch 63/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 132.9951\n",
            "Epoch 64/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 148.2208\n",
            "Epoch 65/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.8337   \n",
            "Epoch 66/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 107.7619\n",
            "Epoch 67/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.8478\n",
            "Epoch 68/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.6294\n",
            "Epoch 69/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98.8861 \n",
            "Epoch 70/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 104.6561\n",
            "Epoch 71/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 123.9046\n",
            "Epoch 72/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 126.3719\n",
            "Epoch 73/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 138.5866\n",
            "Epoch 74/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.1053 \n",
            "Epoch 75/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95.6749 \n",
            "Epoch 76/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84.4874  \n",
            "Epoch 77/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117.3991  \n",
            "Epoch 78/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.9742  \n",
            "Epoch 79/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 154.0476 \n",
            "Epoch 80/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.2342 \n",
            "Epoch 81/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103.9727 \n",
            "Epoch 82/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108.7708 \n",
            "Epoch 83/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101.4121\n",
            "Epoch 84/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117.1470 \n",
            "Epoch 85/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 94.2804 \n",
            "Epoch 86/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 100.5503 \n",
            "Epoch 87/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 133.6126\n",
            "Epoch 88/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.2078\n",
            "Epoch 89/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 147.8903\n",
            "Epoch 90/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.7454\n",
            "Epoch 91/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.1668\n",
            "Epoch 92/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.0890\n",
            "Epoch 93/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 83.0313\n",
            "Epoch 94/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 99.2746\n",
            "Epoch 95/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.8810\n",
            "Epoch 96/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.9611\n",
            "Epoch 97/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.3026\n",
            "Epoch 98/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.4569\n",
            "Epoch 99/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98.1636\n",
            "Epoch 100/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 94.1949\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Resultados do MLP com TensorFlow:\n",
            "RMSE: 11.448036250582112\n",
            "R²: 0.21628080156782747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi realizada a aplicação de um MLP, com uma camada oculta e o cálculo dos neurônios feitos através da regra de Kolgomorov. Na aplicação do modelo foram utilizadas as funções de ativação Sigmoid e Relu para aplicação da não linearidade no modelo, porém a Relu apresentou resultado mais significante.\n",
        "\n",
        "Em relação aos otimizadores, foram utilizados o Adam e sgd para análise, porém o Adam apresentou melhor resultado que o sgd.\n",
        "\n",
        "Como resultado, essa MLP apresentaram os seguintes resultados: RMSE: 11,448 e R²:0.216.\n",
        "\n",
        "Esses resultados foram bem abaixo se comparado aos modelos de regressão linear e ao modelo de Redes Neurais usados no artigo, que foi de: RMSE:7,116 e R²:0,542.\n",
        "\n"
      ],
      "metadata": {
        "id": "XZd77wMd1LNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:,1:7].values\n",
        "y = data.iloc[:,7].values\n",
        "\n",
        "# Aplicando a normalização nas variáveis independentes (X)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste (70% treino, 30% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Definindo a quantidade de neurônios da camada oculta: Regra de Kolmogorov\n",
        "nno = 2 * len(X[0]) + 1\n",
        "\n",
        "# Definindo o modelo MLP com TensorFlow (Keras)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(nno, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(1)  # Camada de saída com 1 neurônio para regressão\n",
        "])\n",
        "\n",
        "# Compilando o modelo (utilizando otimizador Adam e erro quadrático médio como perda)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Treinamento do modelo MLP\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred_mlp = model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo MLP\n",
        "rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))\n",
        "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "\n",
        "# Resultados\n",
        "print(\"Resultados do MLP com TensorFlow:\")\n",
        "print(f\"RMSE: {rmse_mlp}\")\n",
        "print(f\"R²: {r2_mlp}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ClGRjCa6e8",
        "outputId": "8aac1a34-bf87-4647-b212-0f2713a4914a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1667.8473\n",
            "Epoch 2/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1616.5642\n",
            "Epoch 3/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1655.7496\n",
            "Epoch 4/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1628.6500\n",
            "Epoch 5/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1535.4125\n",
            "Epoch 6/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1639.2302\n",
            "Epoch 7/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1566.5857\n",
            "Epoch 8/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1475.5367\n",
            "Epoch 9/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1472.8804\n",
            "Epoch 10/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1422.9642\n",
            "Epoch 11/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1416.0120\n",
            "Epoch 12/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1327.0538\n",
            "Epoch 13/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1219.1603 \n",
            "Epoch 14/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1317.7034 \n",
            "Epoch 15/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1199.8970  \n",
            "Epoch 16/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1249.7778 \n",
            "Epoch 17/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1257.0253 \n",
            "Epoch 18/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1141.7593\n",
            "Epoch 19/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1067.1504 \n",
            "Epoch 20/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1078.3960 \n",
            "Epoch 21/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 961.0231 \n",
            "Epoch 22/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 910.3332  \n",
            "Epoch 23/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 898.7081  \n",
            "Epoch 24/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 924.7354  \n",
            "Epoch 25/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 789.9734 \n",
            "Epoch 26/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 727.1174 \n",
            "Epoch 27/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 747.9515  \n",
            "Epoch 28/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 631.5361  \n",
            "Epoch 29/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 640.4014 \n",
            "Epoch 30/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 603.1660  \n",
            "Epoch 31/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 587.1410  \n",
            "Epoch 32/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 451.6226 \n",
            "Epoch 33/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 515.2221 \n",
            "Epoch 34/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 475.0943 \n",
            "Epoch 35/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 459.4303 \n",
            "Epoch 36/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 441.3858  \n",
            "Epoch 37/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 386.1708  \n",
            "Epoch 38/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 296.7858 \n",
            "Epoch 39/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.8865 \n",
            "Epoch 40/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 270.4435 \n",
            "Epoch 41/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 295.9443 \n",
            "Epoch 42/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.2802 \n",
            "Epoch 43/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 234.5674 \n",
            "Epoch 44/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 240.2229  \n",
            "Epoch 45/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 244.1500  \n",
            "Epoch 46/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 234.9057  \n",
            "Epoch 47/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 202.0285 \n",
            "Epoch 48/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 182.9932 \n",
            "Epoch 49/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.9204  \n",
            "Epoch 50/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 181.4740 \n",
            "Epoch 51/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 176.1527\n",
            "Epoch 52/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 183.6305  \n",
            "Epoch 53/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.4046\n",
            "Epoch 54/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 137.5044\n",
            "Epoch 55/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143.5482\n",
            "Epoch 56/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.7375  \n",
            "Epoch 57/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 143.1113 \n",
            "Epoch 58/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 167.0706  \n",
            "Epoch 59/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 170.7088 \n",
            "Epoch 60/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 165.0829  \n",
            "Epoch 61/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 191.6622  \n",
            "Epoch 62/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 159.1083 \n",
            "Epoch 63/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 139.0116 \n",
            "Epoch 64/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 147.2538  \n",
            "Epoch 65/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 118.8474 \n",
            "Epoch 66/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 180.4665\n",
            "Epoch 67/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116.3819\n",
            "Epoch 68/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117.3621  \n",
            "Epoch 69/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 134.7632  \n",
            "Epoch 70/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128.1586 \n",
            "Epoch 71/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105.5389\n",
            "Epoch 72/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108.2009\n",
            "Epoch 73/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.9870 \n",
            "Epoch 74/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.4215\n",
            "Epoch 75/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 147.9656\n",
            "Epoch 76/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 122.0164  \n",
            "Epoch 77/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.0490 \n",
            "Epoch 78/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112.1394 \n",
            "Epoch 79/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 122.7136\n",
            "Epoch 80/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 101.5246\n",
            "Epoch 81/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.9233 \n",
            "Epoch 82/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95.2823\n",
            "Epoch 83/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.8118\n",
            "Epoch 84/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 91.9561\n",
            "Epoch 85/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.7194\n",
            "Epoch 86/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.6296\n",
            "Epoch 87/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.7979\n",
            "Epoch 88/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98.5635\n",
            "Epoch 89/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 97.1249\n",
            "Epoch 90/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.0197\n",
            "Epoch 91/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.0532\n",
            "Epoch 92/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 83.4287\n",
            "Epoch 93/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 90.5904\n",
            "Epoch 94/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80.3102\n",
            "Epoch 95/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 102.8666\n",
            "Epoch 96/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129.0925\n",
            "Epoch 97/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98.0233  \n",
            "Epoch 98/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109.1611 \n",
            "Epoch 99/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.6204 \n",
            "Epoch 100/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87.6193  \n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Resultados do MLP com TensorFlow:\n",
            "RMSE: 9.668966732569823\n",
            "R²: 0.440939735475547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assim como no modelo Linear, na segunda aplicação foi realizada a normalização dos dados de entrada.\n",
        "\n",
        "Os resultados obtidos apresentaram valores melhores se comparados ao primeiro MLP, com RMSE:9.669 e R²:0.441. Porém ainda aquém do modelo de (Yeh et al.,2018)."
      ],
      "metadata": {
        "id": "I6hFzwlu2y2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:, 1:7].values\n",
        "y = data.iloc[:, 7].values\n",
        "\n",
        "# Aplicando a normalização nas variáveis independentes (X)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Definindo a quantidade de neurônios da camada oculta: Regra de Kolmogorov\n",
        "nno = 2 * len(X[0]) + 1\n",
        "\n",
        "# Configurando a validação cruzada com KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5 dobras\n",
        "rmse_list = []\n",
        "r2_list = []\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Definindo o modelo MLP com TensorFlow (Keras)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(nno, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        tf.keras.layers.Dense(1)  # Camada de saída com 1 neurônio para regressão\n",
        "    ])\n",
        "\n",
        "    # Compilando o modelo\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Treinamento do modelo MLP\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)  # verbose=0 para não mostrar o progresso\n",
        "\n",
        "    # Fazendo previsões no conjunto de teste\n",
        "    y_pred_mlp = model.predict(X_test)\n",
        "\n",
        "    # Avaliação do modelo MLP\n",
        "    rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))\n",
        "    r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "\n",
        "    rmse_list.append(rmse_mlp)\n",
        "    r2_list.append(r2_mlp)\n",
        "\n",
        "# Resultados finais\n",
        "print(\"Resultados do MLP com validação cruzada:\")\n",
        "print(f\"RMSE médio: {np.mean(rmse_list)} ± {np.std(rmse_list)}\")\n",
        "print(f\"R² médio: {np.mean(r2_list)} ± {np.std(r2_list)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8DhWjLRclGs",
        "outputId": "338354ff-c0c6-43ed-894d-95ead476f1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Resultados do MLP com validação cruzada:\n",
            "RMSE médio: 9.346958291785024 ± 1.4773406389212402\n",
            "R² médio: 0.514962268941291 ± 0.10109541133994614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O terceiro teste foi realizada com a aplicação da validação cruzada com 5 Kfolds.\n",
        "\n",
        "As métricas apresentadas geraram valores relativamente melhores do que os apresentados após apenas a normalização."
      ],
      "metadata": {
        "id": "hWEn3rGJ3_JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Carregando os dados do arquivo Excel\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:, 1:7].values\n",
        "y = data.iloc[:, 7].values\n",
        "\n",
        "# Aplicando a normalização nas variáveis independentes (X)\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Aplicando PCA com 95% de retenção de variância\n",
        "pca = PCA(n_components=0.95)  # Mantém 95% da variância\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Definindo a quantidade de neurônios da camada oculta: Regra de Kolmogorov\n",
        "nno = 2 * X_pca.shape[1] + 1  # Usando a nova dimensionalidade após PCA\n",
        "\n",
        "# Configurando a validação cruzada com KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5 dobras\n",
        "rmse_list = []\n",
        "r2_list = []\n",
        "\n",
        "for train_index, test_index in kf.split(X_pca):\n",
        "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Definindo o modelo MLP com TensorFlow (Keras)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(nno, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        tf.keras.layers.Dense(1)  # Camada de saída com 1 neurônio para regressão\n",
        "    ])\n",
        "\n",
        "    # Compilando o modelo\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Treinamento do modelo MLP\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)  # verbose=0 para não mostrar o progresso\n",
        "\n",
        "    # Fazendo previsões no conjunto de teste\n",
        "    y_pred_mlp = model.predict(X_test)\n",
        "\n",
        "    # Avaliação do modelo MLP\n",
        "    rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))\n",
        "    r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "\n",
        "    rmse_list.append(rmse_mlp)\n",
        "    r2_list.append(r2_mlp)\n",
        "\n",
        "# Resultados finais\n",
        "print(\"Resultados do MLP com validação cruzada e PCA:\")\n",
        "print(f\"RMSE médio: {np.mean(rmse_list)} ± {np.std(rmse_list)}\")\n",
        "print(f\"R² médio: {np.mean(r2_list)} ± {np.std(r2_list)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vsuBN25dA1D",
        "outputId": "e6ce3904-5afa-4b3c-b4e5-6d78ceb04713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Resultados do MLP com validação cruzada e PCA:\n",
            "RMSE médio: 8.826770275837486 ± 1.3840779880922134\n",
            "R² médio: 0.5665140135714315 ± 0.09451398552956905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após isso, foi aplicada a técnica de PCA + Validação cruzada.\n",
        "\n",
        "Esse resultado apresentou valores melhores se comparados aos outros modelos de MLP e mais aproximados ao do artigo base de comparação."
      ],
      "metadata": {
        "id": "JEmj9Srv4b5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Modelos| RMSE | R² |\n",
        "|-------|------|----|\n",
        "|MLP|11.448|0.216|\n",
        "|MLP com Normalização|9.669|0.441|\n",
        "|MLP com validação cruzada|9.347 ± 1.477|0.515 ± 0.101|\n",
        "|MLP com validação cruzada e PCA|8.826 ± 1.384|0.566 ± 0.094|\n"
      ],
      "metadata": {
        "id": "Xkeca-Oe-BtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR"
      ],
      "metadata": {
        "id": "ky2blL02f6ZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O SVR tem por objetivo encontrar um hiperplano que melhor separe os dados em um espaço de alta dimensão.  \n"
      ],
      "metadata": {
        "id": "h50xuDbd8Fc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Carregando os dados\n",
        "file_path = '/content/Real estate valuation data set.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Separando as variáveis independentes (X) da dependente (Y)\n",
        "X = data.iloc[:, 1:7].values\n",
        "y = data.iloc[:, 7].values\n",
        "\n",
        "# Normalizando os dados\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste (70% treino, 30% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Definindo o modelo SVR\n",
        "model = SVR()\n",
        "\n",
        "# Definindo a grade de hiperparâmetros, incluindo diferentes kernels\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'epsilon': [0.01, 0.1, 0.5, 1],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Realizando a busca em grade com validação cruzada\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
        "\n",
        "# Ajustando o modelo\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtendo os melhores parâmetros e o melhor modelo\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Fazendo previsões com o melhor modelo\n",
        "y_pred_svr = best_model.predict(X_test)\n",
        "\n",
        "# Avaliação do modelo\n",
        "rmse_svr = np.sqrt(mean_squared_error(y_test, y_pred_svr))\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "# Resultados\n",
        "print(\"Melhores parâmetros encontrados:\")\n",
        "print(best_params)\n",
        "print(\"Resultados do SVR com melhores parâmetros:\")\n",
        "print(f\"RMSE: {rmse_svr}\")\n",
        "print(f\"R²: {r2_svr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Mi3LJUGdjMW",
        "outputId": "52655ab3-e951-4ede-e1f7-9aac2aa52e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n",
            "Melhores parâmetros encontrados:\n",
            "{'C': 100, 'epsilon': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Resultados do SVR com melhores parâmetros:\n",
            "RMSE: 6.946440690358901\n",
            "R²: 0.711448618648256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o modelo SVR foi aplicada a normalização dos dados e uma busca em grade para detectar o melhor hiperparâmetro do modelo.\n",
        "\n",
        "Os hiperparâmetros utilizados foram\n",
        "\n",
        "**Kernel**:['linear', 'poly', 'rbf', 'sigmoid'].\n",
        "\n",
        "Usado para transformar os dados em um espaço de características de alta dimensão. Isso permite que o modelo capture relações não lineares entre as variáveis.\n",
        "\n",
        "**C**: [0.1, 1, 10, 100].\n",
        "\n",
        "Controla a penalização das instâncias que ficam fora da margem de tolerância. Um valor alto de C significa menos tolerância a erros, enquanto um valor baixo significa mais margem de tolerância.\n",
        "\n",
        "**Epsilon (ε)**: [0.01, 0.1, 0.5, 1].\n",
        "\n",
        "Define a faixa de erro onde as previsões são consideradas aceitáveis. As previsões que caem dentro dessa faixa não contribuem para a função de custo.\n",
        "\n",
        "**Gamma (𝛾)**: ['scale', 'auto', 0.001, 0.01, 0.1].\n",
        "\n",
        "O valor de 𝛾 determina a distância em que um ponto de dados influencia os outros. Um valor de 𝛾 mais alto significa que a influência de um ponto de dados se restringe a uma área menor (mais local), enquanto um valor de\n",
        "𝛾 mais baixo significa que a influência é mais ampla (mais global).\n",
        "\n"
      ],
      "metadata": {
        "id": "KKEyedv18lX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Modelos| RMSE |R²|\n",
        "|-------|------|------|\n",
        "|Regressão Linear (Yeh et al.,2018)|8,042|0,396|\n",
        "|Regressão Linear Múltipla |8.577|0.560|\n",
        "|Regressão Linear Múltipla com Normalização|8.577|0.560|\n",
        "|Regressão Linear Validação Cruzada com KFold|8.796 ± 1.315|0.569 ± 0.0914|\n",
        "|Regressão Linear Validação Cruzada após PCA|8.849 ± 1.365|0.565 ± 0.0909|\n",
        "|MLP(Yeh er al.,2018)|7.116|0.542|\n",
        "|MLP|11.448|0.216|\n",
        "|MLP com Normalização|9.669|0.441|\n",
        "|MLP com validação cruzada|9.347 ± 1.477|0.515 ± 0.101|\n",
        "|MLP com validação cruzada e PCA|8.826 ± 1.384|0.566 ± 0.094|\n",
        "|SVR|6.94|0.711|\n"
      ],
      "metadata": {
        "id": "dx_bKGI9C_2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observando todos os modelos aplicados foi possível notar que o modelo SVR apresentou os melhores resultados,até mesmo que os empregados pelo artigo de comparação.\n",
        "\n",
        "O modelo apresentou um RMSE no valor de 6,94 e um coeficiente de determinação de 0.711. Assim o modelo teve uma melhoria nas duas métricas se comparados a todos os outros valores.\n",
        "\n",
        "Para alcançar esse resultado foi utilizado um pré processamento de normalização dos dados de entrada e os seguintes valores de hiperparâmetros:\n",
        "{'C': 100, 'epsilon': 1, 'gamma': 'scale', 'kernel': 'rbf'}"
      ],
      "metadata": {
        "id": "p6gNnnbMD-hX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sCBenkjj6N1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}